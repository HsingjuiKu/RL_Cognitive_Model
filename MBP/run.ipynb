{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "def rs(state, action, a, b, c, d, r, l):\n",
    "    stp = rt = None\n",
    "    if state == a and action == r:\n",
    "        stp, rt = c, 0\n",
    "    elif state == a and action == l:\n",
    "        stp, rt = b, 0\n",
    "    elif state == b:\n",
    "        stp, rt = d, rv + np.random.randn()\n",
    "    return stp, rt\n",
    "\n",
    "\n",
    "def rbar(state, action, a, b, r, l, rv):\n",
    "    if state == a and (action == r or action == l):\n",
    "        return 0\n",
    "    elif state == b:\n",
    "        return rv\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def update(state, action, Q, a, b, c, d, r, l):\n",
    "    maxQ = np.zeros(4)\n",
    "    for s in range(4):\n",
    "        maxQ[s] = np.max(Q[s])\n",
    "    if state == a and action == r:\n",
    "        return maxQ[c]\n",
    "    elif state == a and action == l:\n",
    "        return maxQ[b]\n",
    "    elif state == b:\n",
    "        return maxQ[d]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def zeroQ(Q):\n",
    "    for i in range(4):\n",
    "        Q[i].fill(0.0)\n",
    "\n",
    "def alphat(alpha0, t):\n",
    "    return alpha0 / (1 + 0.001 * t)\n",
    "\n",
    "def softprob(x):\n",
    "    x = x - np.max(x)\n",
    "    x = np.exp(x)\n",
    "    return x / np.sum(x)\n",
    "\n",
    "def argmaxR(x):\n",
    "    p = softmax(1000 * x)\n",
    "    return np.random.choice(np.arange(len(x)), p=p)\n",
    "\n",
    "# define states and actions\n",
    "a, b, c, d = 0, 1, 2, 3\n",
    "l, r = 0, 1\n",
    "\n",
    "rv = -0.1\n",
    "gamma = 0.99\n",
    "alpha0 = 0.1\n",
    "eps = 0.1\n",
    "Exps = 1000\n",
    "Episodes = 2000\n",
    "\n",
    "# Initialization\n",
    "Q = [np.zeros((2,)), np.zeros((8,)), np.zeros((1,)), np.zeros((1,))]\n",
    "zeroQ(Q)\n",
    "\n",
    "QA = [np.copy(q) for q in Q]\n",
    "QB = [np.copy(q) for q in Q]\n",
    "\n",
    "# Get the true solution to the MDP\n",
    "Qnew = deepcopy(Q)\n",
    "zeroQ(Qnew)\n",
    "\n",
    "for _ in range(1000):\n",
    "    for state in [a, b, c, d]:\n",
    "        for action in range(len(Q[state])):\n",
    "            Qnew[state][action] = rbar(state, action, a, b, r, l, rv) + gamma * update(state, action, Q, a, b, c, d, r, l)\n",
    "    Q = deepcopy(Qnew)\n",
    "\n",
    "QmaxTrue = Q[a][l]\n",
    "\n",
    "# Initialize other necessary variables\n",
    "Qend = np.zeros((Exps, Episodes))\n",
    "dQend = np.zeros((Exps, Episodes))\n",
    "sQend = np.zeros((Exps, Episodes))\n",
    "cQend = np.zeros((Exps, Episodes))\n",
    "bQend = np.zeros((Exps, Episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Initialization\n",
    "states = ['A', 'B', 'C', 'D']\n",
    "actions = {\n",
    "    'A': ['Left', 'Right'],\n",
    "    'B': ['Action1', 'Action2', 'Action3', 'Action4', 'Action5', 'Action6', 'Action7', 'Action8']\n",
    "}\n",
    "\n",
    "# Correctly initialize observed_counts only for states with defined actions\n",
    "observed_counts = {\n",
    "    state: {action: {'observed_successes': 0, 'observed_failures': 0} for action in actions.get(state, [])}\n",
    "    for state in states if state in actions\n",
    "}\n",
    "\n",
    "\n",
    "def update_observed_counts(state, action, reward, observed_counts):\n",
    "    \"\"\"\n",
    "    Update the observed successes or failures based on the actual reward.\n",
    "    \"\"\"\n",
    "    if reward > 0:\n",
    "        observed_counts[state][action]['observed_successes'] += 1\n",
    "    else:\n",
    "        observed_counts[state][action]['observed_failures'] += 1\n",
    "\n",
    "\n",
    "def calculate_action_probs(state, observed_counts, actions):\n",
    "    \"\"\"\n",
    "    Calculate action probabilities based on observed successes and failures for the Bayesian approach.\n",
    "    \"\"\"\n",
    "    action_probs = np.zeros(len(actions[state]))\n",
    "    for action_index, action in enumerate(actions[state]):\n",
    "        observed = observed_counts[state][action]\n",
    "        total_successes = observed['observed_successes']\n",
    "        total_failures = observed['observed_failures']\n",
    "        # Bayesian probability calculation\n",
    "        action_prob = (total_successes + 1) / (total_successes + total_failures + 2)  # Adding pseudo-counts\n",
    "        action_probs[action_index] = action_prob\n",
    "    return action_probs\n",
    "\n",
    "\n",
    "epsilon = 0.1\n",
    "# Implementing the Smoothed Q-Learning algorithm\n",
    "actionsBayes = []\n",
    "for experiment in range(Exps):\n",
    "    Q = np.zeros((len(states), max(len(actions[s]) for s in actions)))  # Reset Q values for each experiment\n",
    "    ct = [0]  # Counter for learning rate update\n",
    "    actionsBayes_ex = []\n",
    "\n",
    "    for episode in range(Episodes):\n",
    "        st = 'A'  # Starting state\n",
    "        while True:\n",
    "            if np.random.rand() < epsilon:\n",
    "                at = np.random.choice(actions[st])\n",
    "            else:\n",
    "                action_probs = calculate_action_probs(st, observed_counts, actions)\n",
    "                at = actions[st][np.argmax(action_probs)]\n",
    "\n",
    "            at_index = actions[st].index(at)\n",
    "            st_index = states.index(st)\n",
    "            stp, rt = rs(st_index, at_index, 0, 1, 2, 3, 0, 1)  # Assumed mapping of action indexes\n",
    "            update_observed_counts(st, at, rt, observed_counts)\n",
    "            ct[0] += 1\n",
    "            alpha = alphat(alpha0, ct[0])\n",
    "\n",
    "            # Correct the Q-value update\n",
    "            if stp not in [2, 3]:  # Check if next state is not terminal\n",
    "                next_state_actions = actions[states[stp]]\n",
    "                next_action_probs = calculate_action_probs(states[stp], observed_counts, actions)\n",
    "                expected_future_reward = np.sum(next_action_probs * Q[stp, :len(next_state_actions)])\n",
    "                Q[st_index][at_index] += alpha * (rt + gamma * expected_future_reward - Q[st_index][at_index])\n",
    "            else:\n",
    "                Q[st_index][at_index] += alpha * (rt - Q[st_index][at_index])  # Terminal state\n",
    "\n",
    "            if stp in [2, 3]:  # Terminal states 'C' or 'D'\n",
    "                break\n",
    "            st = states[stp]  # Update state for next iteration\n",
    "\n",
    "        actionsBayes_ex.append(at_index)\n",
    "    actionsBayes.append(actionsBayes_ex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(actionsBayes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 14\u001B[0m\n\u001B[1;32m      5\u001B[0m avg_abs_error_bQ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39mabs(bQend \u001B[38;5;241m-\u001B[39m QmaxTrue), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# min_length = min(\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#     # min(len(sublist) for sublist in actionsQ),\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#                  # min(len(sublist) for sublist in actionsdQ),\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m#                  # min(len(sublist) for sublist in actionssQ),\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m#                  # min(len(sublist) for sublist in actionscQ),\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m#                  min(len(sublist) for sublist in actionsBayes))\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m min_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msublist\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msublist\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mactionsBayes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# print(min_length)\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# actionsQ_trimmed = [sublist[:min_length] for sublist in actionsQ]\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# actionsdQ_trimmed = [sublist[:min_length] for sublist in actionsdQ]\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# actionssQ_trimmed = [sublist[:min_length] for sublist in actionssQ]\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# actionscQ_trimmed = [sublist[:min_length] for sublist in actionscQ]\u001B[39;00m\n\u001B[1;32m     20\u001B[0m actionsbQ_trimmed \u001B[38;5;241m=\u001B[39m [sublist[:min_length] \u001B[38;5;28;01mfor\u001B[39;00m sublist \u001B[38;5;129;01min\u001B[39;00m actionsBayes]\n",
      "\u001B[0;31mTypeError\u001B[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# avg_abs_error_Q = np.mean(np.abs(Qend - QmaxTrue), axis=0)\n",
    "# avg_abs_error_dQ = np.mean(np.abs(dQend - QmaxTrue), axis=0)\n",
    "# avg_abs_error_sQ = np.mean(np.abs(sQend - QmaxTrue), axis=0)\n",
    "# avg_abs_error_cQ = np.mean(np.abs(cQend - QmaxTrue), axis=0)\n",
    "avg_abs_error_bQ = np.mean(np.abs(bQend - QmaxTrue), axis=0)\n",
    "\n",
    "# min_length = min(\n",
    "#     # min(len(sublist) for sublist in actionsQ),\n",
    "#                  # min(len(sublist) for sublist in actionsdQ),\n",
    "#                  # min(len(sublist) for sublist in actionssQ),\n",
    "#                  # min(len(sublist) for sublist in actionscQ),\n",
    "#                  min(len(sublist) for sublist in actionsBayes))\n",
    "\n",
    "min_length = min(min(len(sublist) for sublist in actionsBayes))\n",
    "# print(min_length)\n",
    "# actionsQ_trimmed = [sublist[:min_length] for sublist in actionsQ]\n",
    "# actionsdQ_trimmed = [sublist[:min_length] for sublist in actionsdQ]\n",
    "# actionssQ_trimmed = [sublist[:min_length] for sublist in actionssQ]\n",
    "# actionscQ_trimmed = [sublist[:min_length] for sublist in actionscQ]\n",
    "actionsbQ_trimmed = [sublist[:min_length] for sublist in actionsBayes]\n",
    "# print(actionsQ_trimmed)\n",
    "# avg_action_Q = np.mean([[action == l for action in sublist] for sublist in actionsQ_trimmed], axis=0)\n",
    "# avg_action_dQ = np.mean([[action == l for action in sublist] for sublist in actionsdQ_trimmed], axis=0)\n",
    "# avg_action_sQ = np.mean([[action == l for action in sublist] for sublist in actionssQ_trimmed], axis=0)\n",
    "# avg_action_cQ = np.mean([[action == l for action in sublist] for sublist in actionscQ_trimmed], axis=0)\n",
    "avg_action_bQ = np.mean([[action == l for action in sublist] for sublist in actionsbQ_trimmed], axis=0)\n",
    "\n",
    "# print(avg_action_Q)\n",
    "# print(avg_action_dQ)\n",
    "# print(avg_abs_error_bQ)\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot the average absolute errors for each method\n",
    "# axs[0].plot(avg_abs_error_Q, label='Q learning')\n",
    "# axs[0].plot(avg_abs_error_dQ, label='Double Q learning')\n",
    "# axs[0].plot(avg_abs_error_sQ, label='Smoothed (softmax) Q learning')\n",
    "# axs[0].plot(avg_abs_error_cQ, label='Smoothed (clipmax) Q learning')\n",
    "axs[0].plot(avg_abs_error_bQ, label='Smoothed (Bayes) Q learning')\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Episodes')\n",
    "axs[0].set_ylabel('Average Absolute Error')\n",
    "axs[0].set_title('Comparison of Q Learning Methods')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot the average actions for each method\n",
    "# axs[1].plot(avg_action_Q, label='Q learning')\n",
    "# axs[1].plot(avg_action_dQ, label='Double Q learning')\n",
    "# axs[1].plot(avg_action_sQ, label='Smoothed (softmax) Q learning')\n",
    "# axs[1].plot(avg_action_cQ, label='Smoothed (clipmax) Q learning')\n",
    "axs[1].plot(avg_action_bQ, label='Smoothed (Bayes) Q learning')\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('Episodes')\n",
    "axs[1].set_ylabel('Average Actions')\n",
    "axs[1].set_title('Comparison of Actions in Q Learning Methods')\n",
    "axs[1].grid(True)\n",
    "# Display the figure\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
